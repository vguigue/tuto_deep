{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TE2ItlsI956"
   },
   "source": [
    "# Séance 1 :  Deep Learning - Introduction à Pytorch \n",
    "\n",
    "Les notebooks sont très largement inspirés des cours de **N. Baskiotis et B. Piwowarski**. Ils peuvent être complétés efficacement par les tutoriels *officiels* présents sur le site de pytorch:\n",
    "https://pytorch.org/tutorials/\n",
    "\n",
    "Au niveau de la configuration, toutes les installations doivent fonctionner sur Linux et Mac. Pour windows, ça peut marcher avec Anaconda à jour... Mais il est difficile de récupérer les problèmes.\n",
    "\n",
    "* Aide à la configuration des machines: [lien](https://dac.lip6.fr/master/environnement-deep/)\n",
    "* Alternative 1 à Windows: installer Ubuntu sous Windows:  [Ubuntu WSL](https://ubuntu.com/wsl)\n",
    "* Alternative 2: travailler sur Google Colab (il faut un compte gmail + prendre le temps de comprendre comment accéder à des fichers) [Colab](https://colab.research.google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Y9YOOHHhJKY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de torch est :  2.1.2\n",
      "Le calcul GPU est disponible ?  False\n",
      "Le calcul GPU est disponible (apple) ?  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"La version de torch est : \",torch.__version__)\n",
    "print(\"Le calcul GPU est disponible ? \", torch.cuda.is_available())\n",
    "\n",
    "# pour les possesseurs de mac M1 avec la dernière version de pytorch:\n",
    "print(\"Le calcul GPU est disponible (apple) ? \", torch.backends.mps.is_available())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'exemples :  20640 Dimension :  8\n",
      "Nom des attributs :  MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
      "tensor([[ 8.3252e+00,  4.1000e+01,  6.9841e+00,  1.0238e+00,  3.2200e+02,\n",
      "          2.5556e+00,  3.7880e+01, -1.2223e+02],\n",
      "        [ 8.3014e+00,  2.1000e+01,  6.2381e+00,  9.7188e-01,  2.4010e+03,\n",
      "          2.1098e+00,  3.7860e+01, -1.2222e+02],\n",
      "        [ 7.2574e+00,  5.2000e+01,  8.2881e+00,  1.0734e+00,  4.9600e+02,\n",
      "          2.8023e+00,  3.7850e+01, -1.2224e+02],\n",
      "        [ 5.6431e+00,  5.2000e+01,  5.8174e+00,  1.0731e+00,  5.5800e+02,\n",
      "          2.5479e+00,  3.7850e+01, -1.2225e+02],\n",
      "        [ 3.8462e+00,  5.2000e+01,  6.2819e+00,  1.0811e+00,  5.6500e+02,\n",
      "          2.1815e+00,  3.7850e+01, -1.2225e+02]])\n"
     ]
    }
   ],
   "source": [
    "## Chargement des données housing (depuis sklearn) et transformation en tensor.\n",
    "# from sklearn.datasets import load_housing # => removed\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(data_home=\"./data/\") ## chargement des données\n",
    "\n",
    "housing_x = torch.tensor(housing['data'],dtype=torch.float) # penser à typer les données pour éliminer les incertitudes\n",
    "housing_y = torch.tensor(housing['target'],dtype=torch.float)\n",
    "\n",
    "print(\"Nombre d'exemples : \",housing_x.size(0), \"Dimension : \",housing_x.size(1))\n",
    "print(\"Nom des attributs : \", \", \".join(housing['feature_names']))\n",
    "\n",
    "print(housing_x[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1rxv3ychdhD"
   },
   "source": [
    "## C. Architecture modulaires & réseaux de neurones\n",
    "Dans le framework pytorch (et dans la plupart des frameworks analogues), le module est la brique de base qui permet de construire un réseau de neurones.  Il permet de représenter en particulier :\n",
    "* une couche du réseau (linéaire : **torch.nn.Linear**, convolution : **torch.nn.convXd**, ...)\n",
    "* une fonction d'activation (tanh : **torch.nn.Tanh**, sigmoïde : **torch.nn.Sigmoid** , ReLu : **torch.nn.ReLu**, ...)\n",
    "* une fonction de coût (MSE : **torch.nn.MSELoss**, L1 :  **torch.nn.L1Loss**, CrossEntropy binaire: **torch.BCE**, CrossEntropy : **torch.nn.CrossEntropyLoss**, ...)\n",
    "* mais également des outils de régularisation (BatchNorm : **torch.nn.BatchNorm1d**, Dropout : **torch.nn.Dropout**, ...)\n",
    "* un ensemble de modules : en termes informatique, un module est un conteneur abstrait qui peut contenir d'autres conteneurs) : plusieurs modules peuvent être mis ensemble afin de former un nouveau module plus complexe.\n",
    "\n",
    "\n",
    "Le fonctionnement est très proche des fonctions que nous avons vu ci-dessus (un module encapsule en fait une fonction de **torch.nn.Function**), mais de manière à gérer automatiquement les paramètres à apprendre. Un module est ainsi muni :\n",
    "* d'une méthode **forward** qui permet de calculer la sortie du module à partir des entrées\n",
    "* d'une méthode **backward** qui permet d'effectuer la rétro-propagation (localement).\n",
    "* tous les paramètres sont automatiquement ajoutés dans une liste interne, accessible par la fonction **.parameters()** du module.\n",
    "\n",
    "Ci-dessous un exemple de régression linéaire en utilisant les modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "spguRLUjD60C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sortie du réseau tensor([[46.6159],\n",
      "        [46.1090],\n",
      "        [48.3418],\n",
      "        [47.4171],\n",
      "        [47.0376],\n",
      "        [46.5924],\n",
      "        [47.3076],\n",
      "        [47.2780],\n",
      "        [45.3874],\n",
      "        [47.8787]], grad_fn=<SliceBackward0>)\n",
      "Paramètres et noms des paramètres [(Parameter containing:\n",
      "tensor([[ 0.3182,  0.1469,  0.2202,  0.1892,  0.0012, -0.2181,  0.2230, -0.2297]],\n",
      "       requires_grad=True), ('weight', Parameter containing:\n",
      "tensor([[ 0.3182,  0.1469,  0.2202,  0.1892,  0.0012, -0.2181,  0.2230, -0.2297]],\n",
      "       requires_grad=True))), (Parameter containing:\n",
      "tensor([-0.1469], requires_grad=True), ('bias', Parameter containing:\n",
      "tensor([-0.1469], requires_grad=True)))]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "EPS = 1e-7\n",
    "\n",
    "Xdim = housing_x.size(1)\n",
    "## Création d'une couche linéaire de dimension Xdim->1\n",
    "net = torch.nn.Linear(Xdim, 1) \n",
    "\n",
    "## Passe forward du module :  équivalent à net.forward(x)[:10]\n",
    "print(\"Sortie du réseau\", net(housing_x)[:10])\n",
    "## affiche la liste des paramètres du modèle\n",
    "print(\"Paramètres et noms des paramètres\", list(zip(list(net.parameters()), list(net.named_parameters()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 239054.734375\n",
      "iteration : 1, loss : 26891.689453125\n",
      "iteration : 2, loss : 3063.514404296875\n",
      "iteration : 3, loss : 387.27471923828125\n",
      "iteration : 4, loss : 86.61361694335938\n",
      "iteration : 5, loss : 52.7546272277832\n",
      "iteration : 6, loss : 48.86048889160156\n",
      "iteration : 7, loss : 48.331947326660156\n",
      "iteration : 8, loss : 48.18163299560547\n",
      "iteration : 9, loss : 48.07402420043945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Création d'une fonction de loss aux moindres carrés\n",
    "mseloss = torch.nn.MSELoss()\n",
    "## on créé un optimiseur pour le réseau (paramètres w et b), avec un pas de gradient lr\n",
    "optim = torch.optim.SGD(params=net.parameters(),lr=EPS) \n",
    "# Juste pour info, ce n'est pas utile, les paramètres sont déjà initialisés.\n",
    "net.reset_parameters()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(net(housing_x).view(-1,1),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxdRGqZtSlVt"
   },
   "source": [
    "## C.1. Création d'un réseau de neurones\n",
    "\n",
    "Avec ces briques élémentaires, il est très facile de définir un réseau de neurones standard :\n",
    "* soit en utilisant le conteneur **torch.nn.Sequential** qui permet d'enchaîner séquentiellement plusieurs modules\n",
    "* soit en définissant à la main un nouveau module.\n",
    "\n",
    "Ci-dessous un exemple  pour créer un réseau à deux couches linéaires avec une fonction d'activation tanh des deux manières différentes. Vous remarquez qu'il n'y a pas besoin de définir la méthode **backward**, celle-ci est héritée du conteneur abstrait et ne fait qu'appeler séquentiellement en ordre inverse les méthodes **backward** des différents modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7c6I-PZRD-aN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 5.990405559539795\n",
      "iteration : 1, loss : 4.62723970413208\n",
      "iteration : 2, loss : 3.897770643234253\n",
      "iteration : 3, loss : 3.3290836811065674\n",
      "iteration : 4, loss : 2.886223316192627\n",
      "iteration : 5, loss : 2.5417633056640625\n",
      "iteration : 6, loss : 2.2740321159362793\n",
      "iteration : 7, loss : 2.0660910606384277\n",
      "iteration : 8, loss : 1.9046449661254883\n",
      "iteration : 9, loss : 1.7793229818344116\n",
      "iteration : 10, loss : 1.6820461750030518\n",
      "iteration : 11, loss : 1.606533169746399\n",
      "iteration : 12, loss : 1.5479084253311157\n",
      "iteration : 13, loss : 1.50238835811615\n",
      "iteration : 14, loss : 1.4670363664627075\n",
      "iteration : 15, loss : 1.4395724534988403\n",
      "iteration : 16, loss : 1.4182261228561401\n",
      "iteration : 17, loss : 1.401621699333191\n",
      "iteration : 18, loss : 1.388691782951355\n",
      "iteration : 19, loss : 1.3786100149154663\n",
      "iteration : 20, loss : 1.370739221572876\n",
      "iteration : 21, loss : 1.3645856380462646\n",
      "iteration : 22, loss : 1.3597663640975952\n",
      "iteration : 23, loss : 1.3559852838516235\n",
      "iteration : 24, loss : 1.3530137538909912\n",
      "iteration : 25, loss : 1.3506757020950317\n",
      "iteration : 26, loss : 1.3488332033157349\n",
      "iteration : 27, loss : 1.3473799228668213\n",
      "iteration : 28, loss : 1.3462324142456055\n",
      "iteration : 29, loss : 1.3453257083892822\n",
      "iteration : 30, loss : 1.344609022140503\n",
      "iteration : 31, loss : 1.3440402746200562\n",
      "iteration : 32, loss : 1.3435863256454468\n",
      "iteration : 33, loss : 1.3432204723358154\n",
      "iteration : 34, loss : 1.3429219722747803\n",
      "iteration : 35, loss : 1.342674970626831\n",
      "iteration : 36, loss : 1.3424673080444336\n",
      "iteration : 37, loss : 1.3422895669937134\n",
      "iteration : 38, loss : 1.3421348333358765\n",
      "iteration : 39, loss : 1.3419989347457886\n",
      "iteration : 40, loss : 1.3418781757354736\n",
      "iteration : 41, loss : 1.3417705297470093\n",
      "iteration : 42, loss : 1.3416740894317627\n",
      "iteration : 43, loss : 1.3415884971618652\n",
      "iteration : 44, loss : 1.3415123224258423\n",
      "iteration : 45, loss : 1.3414446115493774\n",
      "iteration : 46, loss : 1.341384768486023\n",
      "iteration : 47, loss : 1.3413316011428833\n",
      "iteration : 48, loss : 1.3412837982177734\n",
      "iteration : 49, loss : 1.3412407636642456\n"
     ]
    }
   ],
   "source": [
    "EPS = 1e-2\n",
    "EPOCHS=50\n",
    "\n",
    "#Réseau à la main (on le refera à la main derriere)\n",
    "class DeuxCouches(torch.nn.Module):\n",
    "  def __init__(self, Xdim):\n",
    "    super(DeuxCouches,self).__init__()\n",
    "    self.un = torch.nn.Linear(Xdim,5)\n",
    "    self.act = torch.nn.Tanh()\n",
    "    self.deux = torch.nn.Linear(5,1)\n",
    "  def forward(self,x):\n",
    "    return self.deux(self.act(self.un(x)))\n",
    "\n",
    "netDeuxCouches = DeuxCouches(Xdim)\n",
    "\n",
    "mseloss = torch.nn.MSELoss()\n",
    "    \n",
    "optim = torch.optim.SGD(params=netDeuxCouches.parameters(),lr=EPS)\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(netDeuxCouches(housing_x),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 4.943875312805176\n",
      "iteration : 1, loss : 4.155421257019043\n",
      "iteration : 2, loss : 3.540735960006714\n",
      "iteration : 3, loss : 3.0612807273864746\n",
      "iteration : 4, loss : 2.687258720397949\n",
      "iteration : 5, loss : 2.3956422805786133\n",
      "iteration : 6, loss : 2.1684842109680176\n",
      "iteration : 7, loss : 1.99144446849823\n",
      "iteration : 8, loss : 1.8532510995864868\n",
      "iteration : 9, loss : 1.7453371286392212\n",
      "iteration : 10, loss : 1.6611653566360474\n",
      "iteration : 11, loss : 1.59550142288208\n",
      "iteration : 12, loss : 1.5441837310791016\n",
      "iteration : 13, loss : 1.5039851665496826\n",
      "iteration : 14, loss : 1.472420573234558\n",
      "iteration : 15, loss : 1.4475315809249878\n",
      "iteration : 16, loss : 1.4277763366699219\n",
      "iteration : 17, loss : 1.4120900630950928\n",
      "iteration : 18, loss : 1.399714469909668\n",
      "iteration : 19, loss : 1.3899340629577637\n",
      "iteration : 20, loss : 1.3821759223937988\n",
      "iteration : 21, loss : 1.3760334253311157\n",
      "iteration : 22, loss : 1.3712000846862793\n",
      "iteration : 23, loss : 1.3674120903015137\n",
      "iteration : 24, loss : 1.3644431829452515\n",
      "iteration : 25, loss : 1.3621079921722412\n",
      "iteration : 26, loss : 1.3602604866027832\n",
      "iteration : 27, loss : 1.3587898015975952\n",
      "iteration : 28, loss : 1.3576102256774902\n",
      "iteration : 29, loss : 1.3566555976867676\n",
      "iteration : 30, loss : 1.3558732271194458\n",
      "iteration : 31, loss : 1.3552207946777344\n",
      "iteration : 32, loss : 1.3546653985977173\n",
      "iteration : 33, loss : 1.3541808128356934\n",
      "iteration : 34, loss : 1.353748083114624\n",
      "iteration : 35, loss : 1.3533555269241333\n",
      "iteration : 36, loss : 1.3529969453811646\n",
      "iteration : 37, loss : 1.3526687622070312\n",
      "iteration : 38, loss : 1.3523682355880737\n",
      "iteration : 39, loss : 1.352091670036316\n",
      "iteration : 40, loss : 1.351834774017334\n",
      "iteration : 41, loss : 1.3515936136245728\n",
      "iteration : 42, loss : 1.3513649702072144\n",
      "iteration : 43, loss : 1.35114586353302\n",
      "iteration : 44, loss : 1.3509347438812256\n",
      "iteration : 45, loss : 1.3507307767868042\n",
      "iteration : 46, loss : 1.3505336046218872\n",
      "iteration : 47, loss : 1.3503433465957642\n",
      "iteration : 48, loss : 1.350158929824829\n",
      "iteration : 49, loss : 1.3499807119369507\n"
     ]
    }
   ],
   "source": [
    "#Création d'un réseau à 1 couche cachée avec le module séquentiel (remplace l'objet précédent)\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "mseloss = torch.nn.MSELoss()    \n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS) # extraction auto des paramètres :)\n",
    "for i in range(EPOCHS):\n",
    "    loss = mseloss(netSeq(housing_x),housing_y.view(-1,1))\n",
    "    print(f\"iteration : {i}, loss : {loss}\")\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGIDLqItECDu"
   },
   "source": [
    "##  C.2. Méthodologie expérimentale et boîte à outils\n",
    "Pytorch dispose d'un ensemble d'outils qui permettent de simplifier les démarches expérimentales. Nous allons voir en particulier : \n",
    "* le DataLoader qui permet de gérer le chargement de données, le partitionement et la constitution d'ensembles de test et d'apprentissage; \n",
    "* le checkpointing qui permet de sauvegarder/charger les modèles en cours d'entraînement.\n",
    "* le TensorBoard (qui vient de tensorflow) qui permet de suivre l'évolution en apprentissage de vos modèles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ4MoJP4k4i0"
   },
   "source": [
    "### C.2.1 DataLoader\n",
    "Le <a href=https://pytorch.org/docs/stable/data.html>**DataLoader**</a> et la classe associée <a href=https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset> **Dataset**</a>  permettent en particulier de :\n",
    "* charger des données\n",
    "* pré-processer les données\n",
    "* de gérer les mini-batchs (sous-ensembles sur lequel on effectue une descente de gradient).\n",
    "\n",
    "La classe **Dataset** est une classe abstraite qui nécessite l'implémentation que d'une seule méthode, ```__getitem__(self,index)``` : elle renvoie le i-ème objet du jeu de données (généralement un couple *(exemple,label)*. \n",
    "\n",
    "La classe **TensorDataset** est l'instanciation la plus courante d'un **Dataset**, elle permet de créer un objet **Dataset** à partir d'une liste de tenseurs qui renvoie pour un index $i$ donné le tuple contenant les $i$-èmes ligne de chaque tenseur.\n",
    "\n",
    "La classe **DataLoader** permet essentiellement de randomiser et de constituer des mini-batchs de façon simple à partir d'une instance de **Dataset**. Chaque mini-batch est constitué d'exemples tirés aléatoirement dans le **Dataset** passé en paramètre et mis bout à bout dans des tenseurs. La méthode ```collate_fn(*args)``` est utilisée pour cela (nous verrons une customization de cette fonction dans une séance ultérieure). C'est ce générateur qui est généralement parcouru lors de l'apprentissage à chaque itération d'optimisation.\n",
    "\n",
    "Voici un exemple de code pour utiliser le DataLoader : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AZaWAFO8k8ze"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      " 20640 (tensor([   4.0368,   52.0000,    4.7617,    1.1036,  413.0000,    2.1399,\n",
      "          37.8500, -122.2500]), tensor(2.6970))\n",
      "DATA LOADER:\n",
      " 1290 \n",
      " torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "## Création d'un dataset à partir des deux tenseurs d'exemples et de labels\n",
    "train_data = TensorDataset(housing_x,housing_y)\n",
    "## On peut indexer et connaitre la longueur d'un dataset\n",
    "print(\"DATASET:\\n\",len(train_data),train_data[5])\n",
    "\n",
    "## Création d'un DataLoader\n",
    "## tailles de mini-batch de 16, shuffle=True permet de mélanger les exemples\n",
    "# loader est un itérateur sur les mini-batchs des données\n",
    "loader = DataLoader(train_data, batch_size=16,shuffle=True ) # n'hésitez pas à jouer avec les paramètres\n",
    "\n",
    "#Premier batch (aléatoire) du dataloader : (nb batch = len/batch_size)\n",
    "print(\"DATA LOADER:\\n\",len(iter(loader)),\"\\n\",next(iter(loader))[0].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p style=\"color: red;\"> EXO: </p>\n",
    "\n",
    "interpréter les dimensions issues du data loader pour être sur que le processus est compris en profondeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0, loss : 2.054494103281073\n",
      "iteration : 1, loss : 1.3646594961599787\n",
      "iteration : 2, loss : 1.3332775475673897\n",
      "iteration : 3, loss : 1.3319214520066283\n",
      "iteration : 4, loss : 1.3318293603584748\n",
      "iteration : 5, loss : 1.3317770278500032\n",
      "iteration : 6, loss : 1.3317842342594797\n",
      "iteration : 7, loss : 1.331741459840952\n",
      "iteration : 8, loss : 1.3317331418510556\n",
      "iteration : 9, loss : 1.33174676486226\n",
      "iteration : 10, loss : 1.3317484919877016\n",
      "iteration : 11, loss : 1.3317398158616798\n",
      "iteration : 12, loss : 1.3317233952671983\n",
      "iteration : 13, loss : 1.3317316486853963\n",
      "iteration : 14, loss : 1.3317024530597434\n",
      "iteration : 15, loss : 1.3316559543558792\n",
      "iteration : 16, loss : 1.3317176057155742\n",
      "iteration : 17, loss : 1.3317243685324986\n",
      "iteration : 18, loss : 1.3317139667942541\n",
      "iteration : 19, loss : 1.3317071904045668\n",
      "iteration : 20, loss : 1.331706804961197\n",
      "iteration : 21, loss : 1.3316891669764999\n",
      "iteration : 22, loss : 1.331718009386876\n",
      "iteration : 23, loss : 1.3316704383423161\n",
      "iteration : 24, loss : 1.331680291613867\n",
      "iteration : 25, loss : 1.3317219387306722\n",
      "iteration : 26, loss : 1.33170726488727\n",
      "iteration : 27, loss : 1.331679192716761\n",
      "iteration : 28, loss : 1.3317115417053533\n",
      "iteration : 29, loss : 1.3317018061645272\n",
      "iteration : 30, loss : 1.3317142843507057\n",
      "iteration : 31, loss : 1.3316989241182342\n",
      "iteration : 32, loss : 1.3317022252914517\n",
      "iteration : 33, loss : 1.3316891310982002\n",
      "iteration : 34, loss : 1.3317067630993304\n",
      "iteration : 35, loss : 1.3316938156189844\n",
      "iteration : 36, loss : 1.3317012733498286\n",
      "iteration : 37, loss : 1.331685218353604\n",
      "iteration : 38, loss : 1.3316994583652926\n",
      "iteration : 39, loss : 1.331696088069169\n",
      "iteration : 40, loss : 1.3316945828208628\n",
      "iteration : 41, loss : 1.3316342880790548\n",
      "iteration : 42, loss : 1.3316980294709981\n",
      "iteration : 43, loss : 1.3316897477983505\n",
      "iteration : 44, loss : 1.3316689001497373\n",
      "iteration : 45, loss : 1.331709803906522\n",
      "iteration : 46, loss : 1.3316914852737456\n",
      "iteration : 47, loss : 1.3316794223563615\n",
      "iteration : 48, loss : 1.331700776794622\n",
      "iteration : 49, loss : 1.331687739791796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPS=1e-4\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "# La boucle d'apprentissage :\n",
    "for i in range(EPOCHS):\n",
    "    cumloss = 0\n",
    "    # On parcourt tous les exemples par batch de 16 (paramètre batch_size de DataLoader)\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item() # item pour un scalaire (sinon .data ou detach)\n",
    "    print(f\"iteration : {i}, loss : {cumloss/len(loader)}\") # loss sur un batch => diviser pour avoir une grandeur interprétable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9x2LC_6lCQm"
   },
   "source": [
    "### C.2.2 Checkpointing\n",
    "Les modèles Deep sont généralement long à apprendre. Afin de ne pas perdre des résultats en cours de calcul, il est fortement recommander de faire du **checkpointing**, c'est-à-dire d'enregistrer des points d'étapes du modèle en cours d'apprentissage pour pouvoir reprendre à n'importe quel moment l'apprentissage du modèle en cas de problème.  Il s'agit en pratique de sauvegarder l'état du modèle et de l'optimisateur (et de tout autre objet qui peut servir lors de l'apprentissage) toutes les n itérations. Toutes les variables d'intérêt sont en général disponibles par la méthode **state_dict()** des modèles et de l'optimiseur. \n",
    "\n",
    "En pratique, vous pouvez utilisé un code dérivé de celui ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URQTq8hrPJO0"
   },
   "outputs": [],
   "source": [
    "# Il existe différentes solutions: en voici une\n",
    "# mais ça marche\n",
    "# \n",
    "import os\n",
    "\n",
    "def save_state(epoch,model,optim,fichier):\n",
    "      \"\"\" sauvegarde du modèle et de l'état de l'optimiseur dans fichier \"\"\"\n",
    "      state = {'epoch' : epoch, 'model_state': model.state_dict(), 'optim_state': optim.state_dict()}\n",
    "      torch.save(state,fichier) # pas besoin de passer par pickle\n",
    " \n",
    "def load_state(fichier,model,optim):\n",
    "      \"\"\" Si le fichier existe, on charge le modèle et l'optimiseur \"\"\"\n",
    "      epoch = 0\n",
    "      if os.path.isfile(fichier):\n",
    "          state = torch.load(fichier)\n",
    "          model.load_state_dict(state['model_state'])\n",
    "          optim.load_state_dict(state['optim_state'])\n",
    "          epoch = state['epoch']\n",
    "      return epoch\n",
    " \n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS) # extraction auto des paramètres\n",
    "fichier = \"/tmp/netSeq.pth\"\n",
    "start_epoch = load_state(fichier,netSeq,optim)\n",
    "for epoch in range(start_epoch,EPOCHS):\n",
    "    cumloss = 0\n",
    "    for bx,by in loader:\n",
    "        loss = mseloss(netSeq(bx).view(-1),by)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        cumloss += loss.item()\n",
    "    if epoch % 10 ==0: save_state(epoch,netSeq,optim,fichier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IstQCvKblSvT"
   },
   "source": [
    "\n",
    "### C.2.3 GPU \n",
    "Afin d'utiliser un GPU lors des calculs, il est nécessaire de transférer les données et le modèle sur le GPU par l'intermédiaire de la fonction **to(device)** des tenseurs et des modules.  Il est impossible de faire une opération lorsqu'une partie des tenseurs sont sur GPU et l'autre sur CPU. Il faut que tous les tenseurs et paramètres soient sur le même device ! On doit donc s'assurer que le modèle, les exemples et les labels sont sur GPU pour faire les opérations.\n",
    "\n",
    "Par ailleurs, on peut connaître le device sur lequel est chargé un tenseur par l'intermédiaire de ```.device``` (mais pas pour un modèle, il faut aller voir les paramètres dans ce cas).\n",
    "\n",
    "Une manière simple d'utiliser un GPU quand il existe et donc d'avoir un code agnostique est la suivante : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs8s7EwwlWTn"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# poru les possesseur de mac MXX:\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "## On charge le modèle sur GPU\n",
    "## A faire avant la déclaration de l'optimiseur, sinon les paramètres optimisés ne seront pas les mêmes! \n",
    "## model =  model.to(device) \n",
    "loader = DataLoader(TensorDataset(housing_x,housing_y), batch_size=16,shuffle=True ) \n",
    "\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netSeq = netSeq.to(device)\n",
    "optim = torch.optim.SGD(params=netSeq.parameters(),lr=EPS)\n",
    "\n",
    "for i,(bx,by) in enumerate(loader):\n",
    "    ## On charge le batch sur GPU\n",
    "    bx, by = bx.to(device), by.to(device)\n",
    "    loss = mseloss(netSeq(bx).view(-1),by)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 10 ==0: print(\"batch \",i)\n",
    "\n",
    "\n",
    "print(\"Device du mini-batch : \", bx.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5J1b55_lFR-"
   },
   "source": [
    "\n",
    "### C.2.4 TensorBoard\n",
    "\n",
    "Durant l'apprentissage de vos modèles, il est agréable de visualiser de quelle manière évolue le coût, la précision sur l'ensemble de validation ainsi que d'autres éléments. TensorFlow dispose d'un outil très apprécié, le TensorBoard, qui permet de gérer très facilement de tels affichages. On retrouve tensorboard dans **Pytorch** dans ```torch.utils.ensorboard``` qui permet de faire le pont de pytorch vers cet outil. \n",
    "\n",
    "Le principe est le suivant :\n",
    "* tensorboard fait tourner en fait un serveur web local qui va lire les fichiers de log dans un répertoire local. L'affichage se fait dans votre navigateur à partir d'un lien fourni lors du lancement de tensorboard.\n",
    "* Les éléments que vous souhaitez visualiser (scalaire, graphes, distributions, histogrammes) sont écrits dans le fichier de log à partir d'un objet **SummaryWriter** .\n",
    "* la méthode ```add_scalar(tag, valeur, global_step)``` permet de logger une valeur à un step donné, ```add_scalar(tag, tag_scalar_dic, global_step)``` un ensemble de valeurs par l'intermédiaire du dictionnaire ```tag_scalar_dic``` (un regroupement des scalaires est fait en fonction du tag passé, chaque sous-tag séparé par un **/**).\n",
    "\n",
    "Il existe d'autres méthodes ```add_XXX``` pour visualiser par exemple des images, des histogrammes (cf <a href=https://pytorch.org/docs/stable/tensorboard.html>la doc </a>).\n",
    "\n",
    "Le code suivant illustre une manière de l'utiliser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1kIhHDnElQd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b7f5b82c5884170\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b7f5b82c5884170\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir /tmp/logs (started 0:00:01 ago; port 6006, pid 49287).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2d2a342afc0ef60\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2d2a342afc0ef60\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 1: Tensorbord à l'interieur du notebook (simple mais pas le plus pratique)\n",
    "\n",
    "# Spécial notebook, les commandes suivantes permettent de lancer tensorboard\n",
    "# En dehors du notebook, il faut le lancer à la main dans le shell : \n",
    "# tensorboard --logdir logs\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /tmp/logs\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Spécial notebook : pour avoir les courbes qui s'affichent dans le notebook, \n",
    "# sinon aller à l'adresse web local indiquée lors du lancement de tensorboard\n",
    "from tensorboard import notebook\n",
    "notebook.display() # A voir si vous avez une autre fenêtre de gestion de tensorboard ou si vous le voulez à la suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir /tmp/logs\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION 2: lancer tensorboard, ecrire des loss (ou autres indicateurs) dans un fichiers + lancer la visu dans dans un navigateur à part\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "\n",
    "# outils avancés de gestion des chemins\n",
    "BASEPATH = Path(\"/tmp\")\n",
    "TB_PATH =  BASEPATH / \"logs\"\n",
    "TB_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# usage externe de tensorboard: (1) lancer la commande dans une console; (2) copier-coller l'URL dans un navigateur\n",
    "display(HTML(\"<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>\"))\n",
    "print(f\"tensorboard --logdir {Path(TB_PATH).absolute()}\")\n",
    "print(\"Once done, copy-paste the localhost url in your browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m cumloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bx, by \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m mseloss(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhousing_x\u001b[49m\u001b[43m)\u001b[49m,housing_y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     20\u001b[0m     optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my-torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my-torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mDeuxCouches.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 12\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeux\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my-torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my-torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my-torch/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "EPS = 1e-5\n",
    "EPOCHS=10\n",
    "netSeq = torch.nn.Sequential(torch.nn.Linear(Xdim,5),torch.nn.Tanh(),torch.nn.Linear(5,1))\n",
    "netDeuxCouches = DeuxCouches()\n",
    "netSeq.name = \"Sequentiel\" # nommer les modèles\n",
    "netDeuxCouches.name = \"DeuxCouches\"\n",
    "\n",
    "\n",
    "mseloss = torch.nn.MSELoss()\n",
    "for model in [netSeq, netDeuxCouches]:\n",
    "    ## Obtention d'un SummaryWriter\n",
    "    ## meme répertoire que la commande %tensorboard --logdir logs \n",
    "    summary = SummaryWriter(f\"/tmp/logs/test/{model.name}/\") # on peut ajouter un timestamp ou des paramètres\n",
    "\n",
    "    optim = torch.optim.SGD(params=model.parameters(),lr=EPS) \n",
    "    for i in range(EPOCHS):\n",
    "        cumloss = 0\n",
    "        for bx, by in loader:\n",
    "            loss = mseloss(model(housing_x),housing_y.view(-1,1))\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()  \n",
    "            cumloss+= loss.item()\n",
    "        summary.add_scalar(f\"loss\",cumloss,i) # c'est ici qu'on fait le lien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "import re\n",
    "# transformation de cet énoncé en version étudiante\n",
    "\n",
    "fname = \"1_3-pytorch-neuralnet-corr.ipynb\" # ce fichier\n",
    "fout  = fname.replace(\"-corr\",\"\")\n",
    "\n",
    "# print(\"Fichier de sortie: \", fout )\n",
    "\n",
    "f = open(fname, \"r\")\n",
    "txt = f.read()\n",
    " \n",
    "f.close()\n",
    "\n",
    "\n",
    "f2 = open(fout, \"w\")\n",
    "f2.write(re.sub(\"<CORRECTION>.*?(</CORRECTION>)\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearning fc TP1 2020-2021-correction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
