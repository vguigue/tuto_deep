{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux convolutionnels pour le traitement de l'image \n",
    "\n",
    "\n",
    "## Partie A : Prise en main des CNN, introspection\n",
    "\n",
    "Vincent Guigue\n",
    "\n",
    "[directement inspiré de:]\n",
    "Nicolas Baskiotis (nicolas.baskiotis@soronne-univeriste.fr) Benjamin Piwowarski (benjamin.piwowarski@sorbonne-universite.fr) -- MLIA/ISIR, Sorbonne Université"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les objectifs de ce module sont :\n",
    "* Prise en main des réseaux convolutionnels (CNN)\n",
    "* Apprentissage d'un CNN\n",
    "* Introspection d'un CNN\n",
    "\n",
    "Nous travaillerons dans un premier temps avec les données MNIST puis avec le jeu de données CIFAR d'images de 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tdqm\n",
      "  Downloading tdqm-0.0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tdqm\n",
      "  Building wheel for tdqm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tdqm: filename=tdqm-0.0.1-py3-none-any.whl size=1323 sha256=7173c90b21c64fa43050822a20b50555459ed4bb05708ed6633ed6cdb52900f2\n",
      "  Stored in directory: /Users/vguigue/Library/Caches/pip/wheels/86/cd/38/f96ed05dd8049e95d8fbeaa0587664eb001a1848979636b771\n",
      "Successfully built tdqm\n",
      "Installing collected packages: tqdm, tdqm\n",
      "Successfully installed tdqm-0.0.1 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "# ! pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OQfQDwsPAGpM"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset,random_split\n",
    "\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prise en main du module sur un exemple jouet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([float(i) for i in range (25)]).view(5,5)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, bias=False) # 1 seul filtre, sans biais pour bien maitriser\n",
    "# note 1: normalement, on laisse TOUJOURS le biais\n",
    "# initialisation à la main pour tester (la procédure normale consiste à laisser l'init aléatoire)\n",
    "poids = torch.tensor([[[[1., 2.],[1., 1.]]]])\n",
    "conv.weight = nn.Parameter(poids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out : tensor([[[ 13.,  18.,  23.,  28.],\n",
      "         [ 38.,  43.,  48.,  53.],\n",
      "         [ 63.,  68.,  73.,  78.],\n",
      "         [ 88.,  93.,  98., 103.]]], grad_fn=<SqueezeBackward1>)\n",
      "filtre :  Parameter containing:\n",
      "tensor([[[[1., 2.],\n",
      "          [1., 1.]]]], requires_grad=True)\n",
      "calcul à la main:  tensor(13.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"out :\", conv(x.unsqueeze(0)))\n",
    "print(\"filtre : \", conv.weight)\n",
    "\n",
    "# explication de la première sortie (= 13)\n",
    "print(\"calcul à la main: \", (x[:2,:2] * poids).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out : tensor([[[  0.,   1.,   3.,   5.,   7.,   4.],\n",
      "         [  5.,  13.,  18.,  23.,  28.,  13.],\n",
      "         [ 20.,  38.,  43.,  48.,  53.,  23.],\n",
      "         [ 35.,  63.,  68.,  73.,  78.,  33.],\n",
      "         [ 50.,  88.,  93.,  98., 103.,  43.],\n",
      "         [ 40.,  62.,  65.,  68.,  71.,  24.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# si on veut ajouter du padding => tout autour => une dimension de plus en sortie\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, bias=False, padding=1, padding_mode='zeros') # 1 seul filtre, sans biais pour bien maitriser\n",
    "# initialisation à la main pour tester (la procédure normale consiste à laisser l'init aléatoire)\n",
    "poids = torch.tensor([[[[1., 2.],[1., 1.]]]])\n",
    "conv.weight = nn.Parameter(poids)\n",
    "\n",
    "print(\"out :\", conv(x.unsqueeze(0))) # essayer d'enlever le unsqueeze + comprendre la logique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out : tensor([[[13., 23.],\n",
      "         [63., 73.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# jouer avec les pas de déplacement de la fenêtre (stride = PAS)\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, bias=False, stride = 2) # 1 seul filtre, sans biais pour bien maitriser\n",
    "# initialisation à la main pour tester (la procédure normale consiste à laisser l'init aléatoire)\n",
    "poids = torch.tensor([[[[1., 2.],[1., 1.]]]])\n",
    "conv.weight = nn.Parameter(poids)\n",
    "\n",
    "print(\"out :\", conv(x.unsqueeze(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out : tensor([[[26., 31., 36.],\n",
      "         [51., 56., 61.],\n",
      "         [76., 81., 86.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# DILATATION - jouer avec les pas de déplacement de la fenêtre (dilation = filtre intermittent)\n",
    "\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, bias=False, dilation = 2) # 1 seul filtre, sans biais pour bien maitriser\n",
    "# initialisation à la main pour tester (la procédure normale consiste à laisser l'init aléatoire)\n",
    "poids = torch.tensor([[[[1., 2.],[1., 1.]]]])\n",
    "conv.weight = nn.Parameter(poids)\n",
    "\n",
    "print(\"out :\", conv(x.unsqueeze(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0539fa28f95d3c31ab10ef7831d62bf0e47751f442c28c9f64a267247464e7da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
