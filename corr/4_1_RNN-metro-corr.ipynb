{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse sequentielle sur des données de métro\n",
    "\n",
    "Objectif: prédire la ville à partir des observations\n",
    "\n",
    "Le jeu de données du métro de Hangzhou décrit le flux entrant et sortant de  80 stations de la ville agrégée par quart d'heure entre $5h30$ et $23h30$ chaque jour. Deux tenseurs sont dans l'archive, un d'apprentissage et l'autre de test. Ils sont  de taille $D\\times T \\times S \\times 2$ avec $D$ le nombre de jour, $T=73$ les tranches successives de quart d'heure entre $5h30$ et $23h30$, $S=80$ le nombre  de stations et les flux entrant et sortant pour la dernière dimension.\n",
    "\n",
    "On va travailler sur un **sous-échantillon pour simplifier les choses**: ce sous-échantillon est paramétré dans les boites ci-dessous.\n",
    "\n",
    "L'architecture du réseau est fournie (dans le fichier annexe utils.py), l'enjeu sera de compléter la fonction standard d'apprentissage pour vous adapter à une architecture définie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RNN, device,SampleMetroDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from itertools import chain\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Chemin vers TensorBoard\n",
    "TB_PATH = \"/tmp/logs\"\n",
    "\n",
    "# TENSORBOARD (en dehors du notebook => Navigateur)\n",
    "# usage externe de tensorboard: (1) lancer la commande dans une console; (2) copier-coller l'URL dans un navigateur\n",
    "display(HTML(\"<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>\"))\n",
    "print(f\"tensorboard --logdir {Path(TB_PATH).absolute()}\")\n",
    "print(\"Une fois la commande lancer dans la console, copier-coller l'URL dans votre navigateur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Chargement d'un sous-échantillon des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de stations utilisé \n",
    "CLASSES = 10\n",
    "#Longueur des séquences \n",
    "LENGTH = 20\n",
    "# Dimension de l'entrée (1 (in) ou 2 (in/out))\n",
    "DIM_INPUT = 2\n",
    "#Taille du batch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH = \"./data/\"\n",
    "\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\",\"rb\"))\n",
    "ds_train = SampleMetroDataset(matrix_train[:, :, :CLASSES, :DIM_INPUT], length=LENGTH)\n",
    "ds_test = SampleMetroDataset(matrix_test[:, :, :CLASSES, :DIM_INPUT], length = LENGTH, stations_max = ds_train.stations_max)\n",
    "data_train = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "data_test = DataLoader(ds_test, batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse des données\n",
    "# quelques propositions... Mais à vous de jouer\n",
    "\n",
    "print(len(ds_train))\n",
    "print(ds_train[0])\n",
    "print(ds_train[0][0].size())\n",
    "\n",
    "cl = [ds_train[i][1] for i in range(len(ds_train))]\n",
    "\n",
    "print(np.unique(cl))\n",
    "print(ds_train[1][0].sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramértage par défaut\n",
    "dim_input=2\n",
    "epochs=100\n",
    "batch_size=32\n",
    "length=20\n",
    "latent=10\n",
    "classes=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du modèle\n",
    "\n",
    "**ATTENTION** Le modèle récurrent est défini dans le fichier joint... Mais vous noterez ici que le décodeur est déclaré à part... Ce qui aura une incidence certaine sur l'inférence du modèle et donc sur la boucle d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(dim_input,latent) # cf code dans utils.py\n",
    "decoder = nn.Linear(latent,classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(chain(rnn.parameters(),decoder.parameters()),lr=0.0001)\n",
    "writer = SummaryWriter(TB_PATH+\"/predictStations-\"+time.asctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Apprentissage\n",
    "\n",
    "L'enjeu est de faire rentrer ce réseau de neurones dans la boucle d'apprentissage classique développée dans les séances précédante.\n",
    "\n",
    "1. Récupérer une boucle d'apprentissage standard dans un TP précédent\n",
    "2. Jouer avec le modèle rnn pour comprendre ses entrées et ses sorties\n",
    "    - vérifier les dimensions de sortie du réseau\n",
    "    - choisir où brancher le décodeur\n",
    "3. Itérer jusqu'à réussir à lancer l'apprentissage\n",
    "\n",
    "Vérifier les performances directement sur tensorboard au bout de l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boucle standard d'apprentissage\n",
    "# \n",
    "\n",
    "\n",
    "def train(rnn, decoder, epochs):\n",
    "    rnn = rnn.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "##<CORRECTION>\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        logging.info(\"Iteration %d\", epoch)\n",
    "        suml = 0\n",
    "        err = 0\n",
    "        for x,y in data_train: \n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            #if dim_input==1:\n",
    "            #    x = x[:,:,0]\n",
    "            h = rnn.forward(x.transpose(0,1))[-1]\n",
    "            yhat = decoder.forward(h)\n",
    "            l = loss(yhat,y)\n",
    "            suml += l/len(data_train)\n",
    "            err += (yhat.max(1)[1]!=y).float().mean().item()*1./len(data_train)\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "        writer.add_scalar('loss/train',suml,epoch)\n",
    "        writer.add_scalar('error/train',err,epoch)\n",
    "        logging.info(\"loss train : %f -- %f\",suml,err)\n",
    "        with torch.no_grad():\n",
    "            l = 0\n",
    "            err=0\n",
    "            for x,y in data_test:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                #if dim_input==1:\n",
    "                #    x = x[:,:,0]\n",
    "                yhat = decoder.forward(rnn.forward(x.transpose(0,1))[-1])\n",
    "                l += loss(yhat,y)/len(data_test)\n",
    "                err+=(yhat.max(1)[1]!=y).double().mean().item()*1./len(data_test)\n",
    "            writer.add_scalar('loss/test',l,epoch)\n",
    "            writer.add_scalar('error/test',err,epoch)\n",
    "            logging.info(\"loss test : %f --%f\",l,err)\n",
    "    return rnn\n",
    "##</CORRECTION>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(rnn, decoder, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des performances\n",
    "\n",
    "Comparer les performances en apprentissage et en test en utilisant le taux de bonne classification à l'issue de l'apprentissage.\n",
    "\n",
    "Le système présente-il des symptomes de sur-apprentissage? Dans l'affirmative, quelle procédure aurait-on pu mettre en place?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<CORRECTION>\n",
    "# inutile dans la correction les erreurs sont calculées pendant l'apprentissage\n",
    "err = 0\n",
    "for x,y in data_train: \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    h = rnn.forward(x.transpose(0,1))[-1]\n",
    "    yhat = decoder.forward(h)\n",
    "    err += (yhat.max(1)[1]!=y).float().mean().item()*1./len(data_train)\n",
    "print(\"Erreur d'apprentissage: \", err)\n",
    "\n",
    "err=0\n",
    "for x,y in data_test:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    yhat = decoder.forward(rnn.forward(x.transpose(0,1))[-1])\n",
    "    err+=(yhat.max(1)[1]!=y).double().mean().item()*1./len(data_test)\n",
    "\n",
    "print(\"Erreur de test: \", err)\n",
    "\n",
    "# il y a beaucoup de sur-apprentissage. A minima, il faut faire de l'early stopping\n",
    "\n",
    "#</CORRECTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Prediction d'affluence\n",
    "\n",
    "L'objectif de cette partie est de faire de la prédiction de séries temporelles : à partir d'une séquence de flux de longueur $t$ pour l'ensemble des stations du jeu de données, on veut prédire le flux à $t+1$, $t+2$, $\\ldots$. Vous entraînerez un RNN commun à toutes les stations qui prend une série dans $\\mathbb{R}^{n\\times 2}$ et  prédit une série dans $\\mathbb{R}^{n\\times 2}$.\n",
    "\n",
    "Que doit-on changer au modèle précédent ? Quel coût est dans ce cas plus adapté que la cross-entropie ? \n",
    "\n",
    " Faire les expériences en faisant varier l'horizon de prédiction (à $t+2$, etc.) et la longueur des séquences en entrée. Vous pouvez comme précédemment  considérer d'abord que le flux entrant, puis le flux entrant et sortant.\n",
    "\n",
    "\n",
    "Dans ce contexte de réseau \\textit{many-to-many}, la supervision peut se faire à chaque étape de la séquence sans attendre la fin de la séquence. La rétro-propagation n'est faîte qu'une fois que toute la séquence a été vue, mais à un instant $t$, le gradient prend en compte l'erreur à ce moment (en fonction de la supervision du décodage) mais également l'erreur des pas de temps d'après qui est cumulée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramértage par défaut\n",
    "dim_input=2\n",
    "epochs=100\n",
    "batch_size=32\n",
    "length=20\n",
    "latent=10\n",
    "classes=10\n",
    "\n",
    "stations = 20\n",
    "length=20\n",
    "length_fc=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RNN, device,  ForecastMetroDataset\n",
    "\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\",\"rb\"))\n",
    "ds_train = ForecastMetroDataset(matrix_train[:,:,:stations,:dim_input],length=length)\n",
    "ds_test  = ForecastMetroDataset(matrix_test[:,:,:stations,:dim_input],length=length,stations_max=stations)\n",
    "\n",
    "data_train = DataLoader(ds_train,batch_size=batch_size,shuffle=True)\n",
    "data_test  = DataLoader(ds_test,batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyser en détail les dimensions des données d'apprentissage pour comprendre comment apprendre sur ces données\n",
    "\n",
    "Votre code doit vous mener à quelque chose comme la figure ci-dessous:\n",
    "\n",
    "![ts-metro](data/xy-teacherforcing.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraire un echantillon du dataset, mesurer les tailles de x et y... Eventuellement faire un plot\n",
    "\n",
    "# <CORRECTION>\n",
    "x,y = ds_train[0]\n",
    "\n",
    "print(\"x:\",x.size())\n",
    "print(\"y:\",y.size())\n",
    "\n",
    "# premieres series du premier batch\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range (4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.plot(x[:,i,0], label=\"x\")\n",
    "    plt.plot(y[:,i,0], label=\"y\")\n",
    "    plt.legend()\n",
    "plt.savefig(\"data/xy-teacherforcing.png\")\n",
    "# </CORRECTION>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on fournit le code du prédicteur qui permet d'exploiter la structure du réseau de neurones\n",
    "# et de ré-injecter la sortie prédite pour prédire les valeurs suivantes\n",
    "\n",
    "# evidemment, le code est dépendant d'un décodeur qu'il faut déinir\n",
    "\n",
    "def forecast(rnn,decoder,x,h=None,length=10):\n",
    "    with torch.no_grad():\n",
    "        if h is None:\n",
    "            h = rnn.hzero(x.size(1)).to(x.device)\n",
    "        h = rnn.forward(x,h)[-1]\n",
    "        x = decoder.forward(h)\n",
    "        yhat = [x]\n",
    "        for i in range(length-1):\n",
    "            x = decoder.forward(rnn.one_step(x,h))\n",
    "            yhat.append(x)\n",
    "    return torch.stack(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du modèle\n",
    "\n",
    "On vous laisse définir le modèle... Etant donné que le décodeur est à part, prendre le temps de réfléchir à la nature du réseau récurrent. Il faut aussi déterminer la loss la mieux adaptée à ce nouveau problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rnn = \n",
    "# decoder =\n",
    "# loss = \n",
    "\n",
    "##<CORRECTION>\n",
    "rnn = RNN(dim_input*stations,latent)\n",
    "decoder = nn.Linear(latent,dim_input*stations)\n",
    "loss = torch.nn.MSELoss()\n",
    "##</CORRECTION>\n",
    "\n",
    "optim = torch.optim.Adam(chain(rnn.parameters(),decoder.parameters()),lr=0.0001)\n",
    "writer = SummaryWriter(PATH+\"/Forecast-\"+time.asctime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, decoder, epochs):\n",
    "##<CORRECTION>\n",
    "    rnn = rnn.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        logging.info(\"Iteration %d\", epoch)\n",
    "        suml = 0\n",
    "        for x,y in data_train:\n",
    "            # x :  batch x length x stations x dim_input\n",
    "            l=0\n",
    "            optim.zero_grad()\n",
    "            x = x.view(x.size(0),x.size(1),-1).to(device)\n",
    "            h = rnn.forward(x.transpose(0,1))\n",
    "            yhat = decoder.forward(h.view(-1,latent)).view(x.size(1), x.size(0), x.size(2))\n",
    "            l+= loss(yhat,y.view(y.size(0),y.size(1),-1).transpose(0,1).to(device))\n",
    "            suml+=l/len(data_train)\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "        writer.add_scalar('loss/train',suml,epoch)\n",
    "        logging.info(\"loss train : %f\",suml)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            l = 0\n",
    "            lf = 0\n",
    "            for x,y in data_test:\n",
    "                x = x.view(x.size(0),x.size(1),-1).to(device)\n",
    "                h = rnn.forward(x.transpose(0,1))\n",
    "                yhat = decoder.forward(h.view(-1,latent)).view(x.size(1),x.size(0),x.size(2))\n",
    "                l += loss(yhat,y.view(y.size(0),y.size(1),-1).transpose(0,1).to(device))/len(data_test)\n",
    "                yhat = forecast(rnn,decoder,x.transpose(0,1)[:-length_fc],length=length_fc)\n",
    "                lf += loss(yhat,y.view(y.size(0),y.size(1),-1).transpose(0,1).to(device)[-length_fc:])/len(data_test)\n",
    "            writer.add_scalar('loss/test',l,epoch)\n",
    "            logging.info(\"loss test : %f\",l)\n",
    "            writer.add_scalar('loss/test_fc',lf,epoch)\n",
    "            logging.info(\"loss test forecast : %f\",lf)\n",
    "##</CORRECTION>\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(rnn, decoder, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrique et exploitation des résultats\n",
    "\n",
    "Quelle métrique vous semble adaptée à ce problème? \n",
    "\n",
    "Ca vaut le coup de tester la MAPE (mean absolute percentage error) et de vérifier les problèmes autour des heures de faible affluence... Pour ensuite regarder ce qui existe comme alternatives (SMAPE, ...)\n",
    "\n",
    "[Mértique alternative](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error)<BR>\n",
    "[lien vers des explications sur les métriques de régression](https://kobia.fr/regression-metrics-quelle-metrique-choisir/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer les métriques en fonction de l'horizon de prédiction\n",
    "\n",
    "Utiliser la méthode `forecast` pour prédire à des horizons supérieurs à 1... Et analyser les métriques en fonction de l'horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "import re\n",
    "# transformation de cet énoncé en version étudiante\n",
    "\n",
    "fname = \"4_1_RNN-metro-corr.ipynb\" # ce fichier\n",
    "fout  = fname.replace(\"-corr\",\"\")\n",
    "\n",
    "# print(\"Fichier de sortie: \", fout )\n",
    "\n",
    "f = open(fname, \"r\")\n",
    "txt = f.read()\n",
    " \n",
    "f.close()\n",
    "\n",
    "f2 = open(fout, \"w\")\n",
    "f2.write(re.sub(\"<CORRECTION>.*?(</CORRECTION>)\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyth-torch-numpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
