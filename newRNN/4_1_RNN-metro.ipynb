{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse sequentielle sur des données de métro\n",
    "\n",
    "Objectif: prédire la ville à partir des observations\n",
    "\n",
    "Le jeu de données du métro de Hangzhou décrit le flux entrant et sortant de  80 stations de la ville agrégée par quart d'heure entre $5h30$ et $23h30$ chaque jour. Deux tenseurs sont dans l'archive, un d'apprentissage et l'autre de test. Ils sont  de taille $D\\times T \\times S \\times 2$ avec $D$ le nombre de jour, $T=73$ les tranches successives de quart d'heure entre $5h30$ et $23h30$, $S=80$ le nombre  de stations et les flux entrant et sortant pour la dernière dimension.\n",
    "\n",
    "On va travailler sur un **sous-échantillon pour simplifier les choses**: ce sous-échantillon est paramétré dans les boites ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RNN, device,SampleMetroDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from itertools import chain\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir /tmp/logs\n",
      "Une fois la commande lancer dans la console, copier-coller l'URL dans votre navigateur\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Chemin vers TensorBoard\n",
    "TB_PATH = \"/tmp/logs\"\n",
    "\n",
    "# TENSORBOARD V2 (outside notebook => Navigateur)\n",
    "# usage externe de tensorboard: (1) lancer la commande dans une console; (2) copier-coller l'URL dans un navigateur\n",
    "display(HTML(\"<h2>Informations</h2><div>Pour visualiser les logs, tapez la commande : </div>\"))\n",
    "print(f\"tensorboard --logdir {Path(TB_PATH).absolute()}\")\n",
    "print(\"Une fois la commande lancer dans la console, copier-coller l'URL dans votre navigateur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Chargement d'un sous-échantillon des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de stations utilisé \n",
    "CLASSES = 10\n",
    "#Longueur des séquences \n",
    "LENGTH = 20\n",
    "# Dimension de l'entrée (1 (in) ou 2 (in/out))\n",
    "DIM_INPUT = 2\n",
    "#Taille du batch\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH = \"./data/\"\n",
    "\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\",\"rb\"))\n",
    "ds_train = SampleMetroDataset(matrix_train[:, :, :CLASSES, :DIM_INPUT], length=LENGTH)\n",
    "ds_test = SampleMetroDataset(matrix_test[:, :, :CLASSES, :DIM_INPUT], length = LENGTH, stations_max = ds_train.stations_max)\n",
    "data_train = DataLoader(ds_train,batch_size=BATCH_SIZE,shuffle=True)\n",
    "data_test = DataLoader(ds_test, batch_size=BATCH_SIZE,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9540\n",
      "(tensor([[0.0000, 0.0040],\n",
      "        [0.0021, 0.0066],\n",
      "        [0.0000, 0.0370],\n",
      "        [0.0021, 0.0529],\n",
      "        [0.1874, 0.0820],\n",
      "        [0.0695, 0.1045],\n",
      "        [0.0737, 0.1984],\n",
      "        [0.0821, 0.1918],\n",
      "        [0.0821, 0.1918],\n",
      "        [0.0968, 0.2421],\n",
      "        [0.1053, 0.2500],\n",
      "        [0.1095, 0.2659],\n",
      "        [0.1621, 0.2526],\n",
      "        [0.1937, 0.3135],\n",
      "        [0.1937, 0.2884],\n",
      "        [0.2168, 0.3836],\n",
      "        [0.2674, 0.3082],\n",
      "        [0.2168, 0.3889],\n",
      "        [0.2632, 0.3161],\n",
      "        [0.3663, 0.3796]]), 0)\n",
      "torch.Size([20, 2])\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "tensor([3.7095, 8.4339])\n"
     ]
    }
   ],
   "source": [
    "# analyse des données\n",
    "# quelques proposition... Mais à vous de jouer\n",
    "\n",
    "print(len(ds_train))\n",
    "print(ds_train[0])\n",
    "print(ds_train[0][0].size())\n",
    "\n",
    "cl = [ds_train[i][1] for i in range(len(ds_train))]\n",
    "\n",
    "print(np.unique(cl))\n",
    "print(ds_train[1][0].sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paramértage par défaut\n",
    "dim_input=2\n",
    "epochs=100\n",
    "batch_size=32\n",
    "length=20\n",
    "latent=10\n",
    "classes=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(dim_input,latent) # cf code dans utils.py\n",
    "decoder = nn.Linear(latent,classes)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(chain(rnn.parameters(),decoder.parameters()),lr=0.0001)\n",
    "writer = SummaryWriter(TB_PATH+\"/predictStations-\"+time.asctime())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Apprentissage\n",
    "\n",
    "L'enjeu est de faire rentrer ce réseau de neurones dans la boucle d'apprentissage classique développée dans les séances précédante.\n",
    "\n",
    "1. Récupérer une boucle d'apprentissage standard dans un TP précédent\n",
    "2. Jouer avec le modèle rnn pour comprendre ses entrées et ses sorties\n",
    "    - vérifier les dimensions de sortie du réseau\n",
    "    - choisir où brancher le décodeur\n",
    "3. Itérer jusqu'à réussir à lancer l'apprentissage\n",
    "\n",
    "Vérifier les performances directement sur tensorboard au bout de l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boucle standard d'apprentissage\n",
    "# \n",
    "\n",
    "\n",
    "def train(rnn, decoder, epochs):\n",
    "    rnn = rnn.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "## TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:loss train : 2.335583 -- 0.900293\n",
      "INFO:root:loss test : 2.312457 --0.900054\n",
      "INFO:root:Iteration 1\n",
      "INFO:root:loss train : 2.299029 -- 0.898620\n",
      "INFO:root:loss test : 2.280795 --0.887931\n",
      "INFO:root:Iteration 2\n",
      "INFO:root:loss train : 2.271045 -- 0.884197\n",
      "INFO:root:loss test : 2.251405 --0.847791\n",
      "INFO:root:Iteration 3\n",
      "INFO:root:loss train : 2.236055 -- 0.843645\n",
      "INFO:root:loss test : 2.199703 --0.823815\n",
      "INFO:root:Iteration 4\n",
      "INFO:root:loss train : 2.159901 -- 0.826505\n",
      "INFO:root:loss test : 2.111423 --0.830550\n",
      "INFO:root:Iteration 5\n",
      "INFO:root:loss train : 2.098709 -- 0.839674\n",
      "INFO:root:loss test : 2.078041 --0.839709\n",
      "INFO:root:Iteration 6\n",
      "INFO:root:loss train : 2.072749 -- 0.839360\n",
      "INFO:root:loss test : 2.056861 --0.838901\n",
      "INFO:root:Iteration 7\n",
      "INFO:root:loss train : 2.054338 -- 0.836957\n",
      "INFO:root:loss test : 2.040826 --0.828664\n",
      "INFO:root:Iteration 8\n",
      "INFO:root:loss train : 2.038416 -- 0.823892\n",
      "INFO:root:loss test : 2.024000 --0.812231\n",
      "INFO:root:Iteration 9\n",
      "INFO:root:loss train : 2.024842 -- 0.805288\n",
      "INFO:root:loss test : 2.009197 --0.810614\n",
      "INFO:root:Iteration 10\n",
      "INFO:root:loss train : 2.012117 -- 0.780414\n",
      "INFO:root:loss test : 1.996713 --0.769935\n",
      "INFO:root:Iteration 11\n",
      "INFO:root:loss train : 1.999259 -- 0.739026\n",
      "INFO:root:loss test : 1.985357 --0.740302\n",
      "INFO:root:Iteration 12\n",
      "INFO:root:loss train : 1.987293 -- 0.739130\n",
      "INFO:root:loss test : 1.976896 --0.752694\n",
      "INFO:root:Iteration 13\n",
      "INFO:root:loss train : 1.978568 -- 0.747178\n",
      "INFO:root:loss test : 1.965628 --0.759159\n",
      "INFO:root:Iteration 14\n",
      "INFO:root:loss train : 1.968749 -- 0.755017\n",
      "INFO:root:loss test : 1.957074 --0.757812\n",
      "INFO:root:Iteration 15\n",
      "INFO:root:loss train : 1.959259 -- 0.755226\n",
      "INFO:root:loss test : 1.951439 --0.765625\n",
      "INFO:root:Iteration 16\n",
      "INFO:root:loss train : 1.952563 -- 0.756375\n",
      "INFO:root:loss test : 1.941044 --0.764278\n",
      "INFO:root:Iteration 17\n",
      "INFO:root:loss train : 1.944067 -- 0.750000\n",
      "INFO:root:loss test : 1.936176 --0.766164\n",
      "INFO:root:Iteration 18\n",
      "INFO:root:loss train : 1.938002 -- 0.752613\n",
      "INFO:root:loss test : 1.929668 --0.768588\n",
      "INFO:root:Iteration 19\n",
      "INFO:root:loss train : 1.932714 -- 0.748223\n",
      "INFO:root:loss test : 1.923401 --0.767511\n",
      "INFO:root:Iteration 20\n",
      "INFO:root:loss train : 1.925510 -- 0.749477\n",
      "INFO:root:loss test : 1.917373 --0.765894\n",
      "INFO:root:Iteration 21\n",
      "INFO:root:loss train : 1.920291 -- 0.747283\n",
      "INFO:root:loss test : 1.915458 --0.763200\n",
      "INFO:root:Iteration 22\n",
      "INFO:root:loss train : 1.915822 -- 0.744983\n",
      "INFO:root:loss test : 1.910010 --0.764278\n",
      "INFO:root:Iteration 23\n",
      "INFO:root:loss train : 1.912221 -- 0.743938\n",
      "INFO:root:loss test : 1.906456 --0.758351\n",
      "INFO:root:Iteration 24\n",
      "INFO:root:loss train : 1.906632 -- 0.739026\n",
      "INFO:root:loss test : 1.901713 --0.761045\n",
      "INFO:root:Iteration 25\n",
      "INFO:root:loss train : 1.902671 -- 0.740071\n",
      "INFO:root:loss test : 1.898014 --0.759429\n",
      "INFO:root:Iteration 26\n",
      "INFO:root:loss train : 1.898126 -- 0.733696\n",
      "INFO:root:loss test : 1.897904 --0.757004\n",
      "INFO:root:Iteration 27\n",
      "INFO:root:loss train : 1.894201 -- 0.729202\n",
      "INFO:root:loss test : 1.893344 --0.756466\n",
      "INFO:root:Iteration 28\n",
      "INFO:root:loss train : 1.890358 -- 0.727320\n",
      "INFO:root:loss test : 1.888263 --0.752425\n",
      "INFO:root:Iteration 29\n",
      "INFO:root:loss train : 1.887652 -- 0.723349\n",
      "INFO:root:loss test : 1.888129 --0.746228\n",
      "INFO:root:Iteration 30\n",
      "INFO:root:loss train : 1.883582 -- 0.715928\n",
      "INFO:root:loss test : 1.882397 --0.744073\n",
      "INFO:root:Iteration 31\n",
      "INFO:root:loss train : 1.877711 -- 0.712061\n",
      "INFO:root:loss test : 1.880494 --0.742187\n",
      "INFO:root:Iteration 32\n",
      "INFO:root:loss train : 1.873932 -- 0.709030\n",
      "INFO:root:loss test : 1.877370 --0.742187\n",
      "INFO:root:Iteration 33\n",
      "INFO:root:loss train : 1.870844 -- 0.705581\n",
      "INFO:root:loss test : 1.870685 --0.734375\n",
      "INFO:root:Iteration 34\n",
      "INFO:root:loss train : 1.866066 -- 0.699833\n",
      "INFO:root:loss test : 1.866853 --0.734375\n",
      "INFO:root:Iteration 35\n",
      "INFO:root:loss train : 1.862735 -- 0.701714\n",
      "INFO:root:loss test : 1.863148 --0.725216\n",
      "INFO:root:Iteration 36\n",
      "INFO:root:loss train : 1.858022 -- 0.694293\n",
      "INFO:root:loss test : 1.861213 --0.727640\n",
      "INFO:root:Iteration 37\n",
      "INFO:root:loss train : 1.852636 -- 0.689381\n",
      "INFO:root:loss test : 1.860560 --0.730334\n",
      "INFO:root:Iteration 38\n",
      "INFO:root:loss train : 1.848199 -- 0.691054\n",
      "INFO:root:loss test : 1.853637 --0.726024\n",
      "INFO:root:Iteration 39\n",
      "INFO:root:loss train : 1.843630 -- 0.684992\n",
      "INFO:root:loss test : 1.848480 --0.721175\n",
      "INFO:root:Iteration 40\n",
      "INFO:root:loss train : 1.838367 -- 0.682065\n",
      "INFO:root:loss test : 1.844650 --0.719828\n",
      "INFO:root:Iteration 41\n",
      "INFO:root:loss train : 1.832702 -- 0.680497\n",
      "INFO:root:loss test : 1.838963 --0.716325\n",
      "INFO:root:Iteration 42\n",
      "INFO:root:loss train : 1.827610 -- 0.679766\n",
      "INFO:root:loss test : 1.830181 --0.708244\n",
      "INFO:root:Iteration 43\n",
      "INFO:root:loss train : 1.819997 -- 0.672241\n",
      "INFO:root:loss test : 1.828285 --0.715248\n",
      "INFO:root:Iteration 44\n",
      "INFO:root:loss train : 1.813099 -- 0.668687\n",
      "INFO:root:loss test : 1.816399 --0.704741\n",
      "INFO:root:Iteration 45\n",
      "INFO:root:loss train : 1.803719 -- 0.664925\n",
      "INFO:root:loss test : 1.807316 --0.697737\n",
      "INFO:root:Iteration 46\n",
      "INFO:root:loss train : 1.794905 -- 0.661476\n",
      "INFO:root:loss test : 1.798190 --0.693966\n",
      "INFO:root:Iteration 47\n",
      "INFO:root:loss train : 1.781842 -- 0.658445\n",
      "INFO:root:loss test : 1.786280 --0.689655\n",
      "INFO:root:Iteration 48\n",
      "INFO:root:loss train : 1.767879 -- 0.657400\n",
      "INFO:root:loss test : 1.770623 --0.681304\n",
      "INFO:root:Iteration 49\n",
      "INFO:root:loss train : 1.748997 -- 0.652696\n",
      "INFO:root:loss test : 1.747175 --0.676455\n",
      "INFO:root:Iteration 50\n",
      "INFO:root:loss train : 1.722594 -- 0.643708\n",
      "INFO:root:loss test : 1.740632 --0.670797\n",
      "INFO:root:Iteration 51\n",
      "INFO:root:loss train : 1.691004 -- 0.633675\n",
      "INFO:root:loss test : 1.697588 --0.660830\n",
      "INFO:root:Iteration 52\n",
      "INFO:root:loss train : 1.657982 -- 0.625209\n",
      "INFO:root:loss test : 1.699784 --0.659483\n",
      "INFO:root:Iteration 53\n",
      "INFO:root:loss train : 1.640837 -- 0.629808\n",
      "INFO:root:loss test : 1.677612 --0.655711\n",
      "INFO:root:Iteration 54\n",
      "INFO:root:loss train : 1.628247 -- 0.625836\n",
      "INFO:root:loss test : 1.671722 --0.657328\n",
      "INFO:root:Iteration 55\n",
      "INFO:root:loss train : 1.617829 -- 0.626568\n",
      "INFO:root:loss test : 1.650869 --0.657328\n",
      "INFO:root:Iteration 56\n",
      "INFO:root:loss train : 1.609358 -- 0.625105\n",
      "INFO:root:loss test : 1.666826 --0.655172\n",
      "INFO:root:Iteration 57\n",
      "INFO:root:loss train : 1.600783 -- 0.625314\n",
      "INFO:root:loss test : 1.645794 --0.655981\n",
      "INFO:root:Iteration 58\n",
      "INFO:root:loss train : 1.593979 -- 0.625941\n",
      "INFO:root:loss test : 1.642255 --0.653017\n",
      "INFO:root:Iteration 59\n",
      "INFO:root:loss train : 1.587965 -- 0.625523\n",
      "INFO:root:loss test : 1.621686 --0.655442\n",
      "INFO:root:Iteration 60\n",
      "INFO:root:loss train : 1.580501 -- 0.621969\n",
      "INFO:root:loss test : 1.625015 --0.649784\n",
      "INFO:root:Iteration 61\n",
      "INFO:root:loss train : 1.576114 -- 0.625000\n",
      "INFO:root:loss test : 1.629053 --0.648976\n",
      "INFO:root:Iteration 62\n",
      "INFO:root:loss train : 1.568992 -- 0.620610\n",
      "INFO:root:loss test : 1.610592 --0.649246\n",
      "INFO:root:Iteration 63\n",
      "INFO:root:loss train : 1.563097 -- 0.620506\n",
      "INFO:root:loss test : 1.607735 --0.647360\n",
      "INFO:root:Iteration 64\n",
      "INFO:root:loss train : 1.559840 -- 0.619356\n",
      "INFO:root:loss test : 1.618991 --0.640625\n",
      "INFO:root:Iteration 65\n",
      "INFO:root:loss train : 1.554815 -- 0.621342\n",
      "INFO:root:loss test : 1.605335 --0.644127\n",
      "INFO:root:Iteration 66\n",
      "INFO:root:loss train : 1.549873 -- 0.618416\n",
      "INFO:root:loss test : 1.608726 --0.640356\n",
      "INFO:root:Iteration 67\n",
      "INFO:root:loss train : 1.546447 -- 0.615176\n",
      "INFO:root:loss test : 1.599869 --0.640625\n",
      "INFO:root:Iteration 68\n",
      "INFO:root:loss train : 1.541459 -- 0.610577\n",
      "INFO:root:loss test : 1.603182 --0.639009\n",
      "INFO:root:Iteration 69\n",
      "INFO:root:loss train : 1.538388 -- 0.609323\n",
      "INFO:root:loss test : 1.602685 --0.639817\n",
      "INFO:root:Iteration 70\n",
      "INFO:root:loss train : 1.535979 -- 0.612667\n",
      "INFO:root:loss test : 1.591020 --0.638739\n",
      "INFO:root:Iteration 71\n",
      "INFO:root:loss train : 1.531280 -- 0.609009\n",
      "INFO:root:loss test : 1.581584 --0.633621\n",
      "INFO:root:Iteration 72\n",
      "INFO:root:loss train : 1.527514 -- 0.609323\n",
      "INFO:root:loss test : 1.591971 --0.635506\n",
      "INFO:root:Iteration 73\n",
      "INFO:root:loss train : 1.521931 -- 0.602947\n",
      "INFO:root:loss test : 1.573988 --0.633621\n",
      "INFO:root:Iteration 74\n",
      "INFO:root:loss train : 1.522755 -- 0.606501\n",
      "INFO:root:loss test : 1.584402 --0.632274\n",
      "INFO:root:Iteration 75\n",
      "INFO:root:loss train : 1.519051 -- 0.604620\n",
      "INFO:root:loss test : 1.575407 --0.632274\n",
      "INFO:root:Iteration 76\n",
      "INFO:root:loss train : 1.515278 -- 0.603888\n",
      "INFO:root:loss test : 1.594095 --0.629849\n",
      "INFO:root:Iteration 77\n",
      "INFO:root:loss train : 1.512644 -- 0.600021\n",
      "INFO:root:loss test : 1.571494 --0.632543\n",
      "INFO:root:Iteration 78\n",
      "INFO:root:loss train : 1.510268 -- 0.602425\n",
      "INFO:root:loss test : 1.586874 --0.630388\n",
      "INFO:root:Iteration 79\n",
      "INFO:root:loss train : 1.507837 -- 0.602947\n",
      "INFO:root:loss test : 1.571295 --0.632543\n",
      "INFO:root:Iteration 80\n",
      "INFO:root:loss train : 1.505423 -- 0.598871\n",
      "INFO:root:loss test : 1.568070 --0.632004\n",
      "INFO:root:Iteration 81\n",
      "INFO:root:loss train : 1.502621 -- 0.599080\n",
      "INFO:root:loss test : 1.567214 --0.631466\n",
      "INFO:root:Iteration 82\n",
      "INFO:root:loss train : 1.507260 -- 0.599498\n",
      "INFO:root:loss test : 1.554334 --0.628772\n",
      "INFO:root:Iteration 83\n",
      "INFO:root:loss train : 1.496639 -- 0.598871\n",
      "INFO:root:loss test : 1.567391 --0.628502\n",
      "INFO:root:Iteration 84\n",
      "INFO:root:loss train : 1.496163 -- 0.596572\n",
      "INFO:root:loss test : 1.577583 --0.622575\n",
      "INFO:root:Iteration 85\n",
      "INFO:root:loss train : 1.493819 -- 0.598558\n",
      "INFO:root:loss test : 1.573375 --0.626616\n",
      "INFO:root:Iteration 86\n",
      "INFO:root:loss train : 1.491653 -- 0.599707\n",
      "INFO:root:loss test : 1.563890 --0.625539\n",
      "INFO:root:Iteration 87\n",
      "INFO:root:loss train : 1.488342 -- 0.593959\n",
      "INFO:root:loss test : 1.569485 --0.619343\n",
      "INFO:root:Iteration 88\n",
      "INFO:root:loss train : 1.485187 -- 0.594586\n",
      "INFO:root:loss test : 1.565202 --0.625000\n",
      "INFO:root:Iteration 89\n",
      "INFO:root:loss train : 1.484362 -- 0.595109\n",
      "INFO:root:loss test : 1.548488 --0.622845\n",
      "INFO:root:Iteration 90\n",
      "INFO:root:loss train : 1.482055 -- 0.592287\n",
      "INFO:root:loss test : 1.563857 --0.618804\n",
      "INFO:root:Iteration 91\n",
      "INFO:root:loss train : 1.479267 -- 0.590615\n",
      "INFO:root:loss test : 1.552335 --0.616379\n",
      "INFO:root:Iteration 92\n",
      "INFO:root:loss train : 1.478112 -- 0.595736\n",
      "INFO:root:loss test : 1.542415 --0.625269\n",
      "INFO:root:Iteration 93\n",
      "INFO:root:loss train : 1.475538 -- 0.590406\n",
      "INFO:root:loss test : 1.557766 --0.617996\n",
      "INFO:root:Iteration 94\n",
      "INFO:root:loss train : 1.473749 -- 0.588629\n",
      "INFO:root:loss test : 1.558272 --0.616379\n",
      "INFO:root:Iteration 95\n",
      "INFO:root:loss train : 1.474946 -- 0.589256\n",
      "INFO:root:loss test : 1.552380 --0.613685\n",
      "INFO:root:Iteration 96\n",
      "INFO:root:loss train : 1.469786 -- 0.584657\n",
      "INFO:root:loss test : 1.550340 --0.610183\n",
      "INFO:root:Iteration 97\n",
      "INFO:root:loss train : 1.466169 -- 0.583089\n",
      "INFO:root:loss test : 1.532060 --0.615571\n",
      "INFO:root:Iteration 98\n",
      "INFO:root:loss train : 1.463676 -- 0.578177\n",
      "INFO:root:loss test : 1.561652 --0.611800\n",
      "INFO:root:Iteration 99\n",
      "INFO:root:loss train : 1.462749 -- 0.576714\n",
      "INFO:root:loss test : 1.532909 --0.610722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Linear(in_features=2, out_features=10, bias=True)\n",
       "  (latent): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(rnn, decoder, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Prediction d'affluence\n",
    "\n",
    "L'objectif de cette partie est de faire de la prédiction de séries temporelles : à partir d'une séquence de flux de longueur $t$ pour l'ensemble des stations du jeu de données, on veut prédire le flux à $t+1$, $t+2$, $\\ldots$. Vous entraînerez un RNN commun à toutes les stations qui prend une série dans $\\mathbb{R}^{n\\times 2}$ et  prédit une série dans $\\mathbb{R}^{n\\times 2}$.\n",
    "\n",
    "Que doit-on changer au modèle précédent ? Quel coût est dans ce cas plus adapté que la cross-entropie ? \n",
    "\n",
    " Faire les expériences en faisant varier l'horizon de prédiction (à $t+2$, etc.) et la longueur des séquences en entrée. Vous pouvez comme précédemment  considérer d'abord que le flux entrant, puis le flux entrant et sortant.\n",
    "\n",
    "\n",
    "Dans ce contexte de réseau \\textit{many-to-many}, la supervision peut se faire à chaque étape de la séquence sans attendre la fin de la séquence. La rétro-propagation n'est faîte qu'une fois que toute la séquence a été vue, mais à un instant $t$, le gradient prend en compte l'erreur à ce moment (en fonction de la supervision du décodage) mais également l'erreur des pas de temps d'après qui est cumulée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramértage par défaut\n",
    "dim_input=2\n",
    "epochs=100\n",
    "batch_size=32\n",
    "length=20\n",
    "latent=10\n",
    "classes=10\n",
    "\n",
    "stations = 20\n",
    "length=20\n",
    "length_fc=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import RNN, device,  ForecastMetroDataset\n",
    "\n",
    "matrix_train, matrix_test = torch.load(open(PATH+\"hzdataset.pch\",\"rb\"))\n",
    "data_train = DataLoader(ForecastMetroDataset(matrix_train[:,:,:stations,:dim_input],length=length),batch_size=batch_size,shuffle=True)\n",
    "data_test = DataLoader(ForecastMetroDataset(matrix_test[:,:,:stations,:dim_input],length=length,stations_max=stations),batch_size=batch_size,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on fournit le code du prédicteur qui permet d'exploiter la structure du réseau de neurones\n",
    "# et de ré-injecter la sortie prédite pour prédire les valeurs suivantes\n",
    "\n",
    "# evidemment, le code est dépendant d'un décodeur qu'il faut déinir\n",
    "\n",
    "def forecast(rnn,decoder,x,h=None,length=10):\n",
    "    with torch.no_grad():\n",
    "        if h is None:\n",
    "            h = rnn.hzero(x.size(1)).to(x.device)\n",
    "        h = rnn.forward(x,h)[-1]\n",
    "        x = decoder.forward(h)\n",
    "        yhat = [x]\n",
    "        for i in range(length-1):\n",
    "            x = decoder.forward(rnn.one_step(x,h))\n",
    "            yhat.append(x)\n",
    "    return torch.stack(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rnn = \n",
    "# decoder =\n",
    "# loss = \n",
    "\n",
    "## TODO \n",
    "\n",
    "optim = torch.optim.Adam(chain(rnn.parameters(),decoder.parameters()),lr=0.0001)\n",
    "writer = SummaryWriter(PATH+\"/Forecast-\"+time.asctime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, decoder, epochs):\n",
    "## TODO \n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Iteration 0\n",
      "INFO:root:loss train : 0.148785\n",
      "INFO:root:loss test : 815.944580\n",
      "INFO:root:loss test forecast : 759.390625\n",
      "INFO:root:Iteration 1\n",
      "INFO:root:loss train : 0.135398\n",
      "INFO:root:loss test : 815.960754\n",
      "INFO:root:loss test forecast : 759.082947\n",
      "INFO:root:Iteration 2\n",
      "INFO:root:loss train : 0.124324\n",
      "INFO:root:loss test : 816.228821\n",
      "INFO:root:loss test forecast : 758.646912\n",
      "INFO:root:Iteration 3\n",
      "INFO:root:loss train : 0.115152\n",
      "INFO:root:loss test : 816.694824\n",
      "INFO:root:loss test forecast : 758.198303\n",
      "INFO:root:Iteration 4\n",
      "INFO:root:loss train : 0.106993\n",
      "INFO:root:loss test : 817.152039\n",
      "INFO:root:loss test forecast : 757.779175\n",
      "INFO:root:Iteration 5\n",
      "INFO:root:loss train : 0.099838\n",
      "INFO:root:loss test : 817.403931\n",
      "INFO:root:loss test forecast : 757.440735\n",
      "INFO:root:Iteration 6\n",
      "INFO:root:loss train : 0.093112\n",
      "INFO:root:loss test : 817.561829\n",
      "INFO:root:loss test forecast : 757.176392\n",
      "INFO:root:Iteration 7\n",
      "INFO:root:loss train : 0.087045\n",
      "INFO:root:loss test : 817.452515\n",
      "INFO:root:loss test forecast : 756.808105\n",
      "INFO:root:Iteration 8\n",
      "INFO:root:loss train : 0.081269\n",
      "INFO:root:loss test : 817.130005\n",
      "INFO:root:loss test forecast : 756.495178\n",
      "INFO:root:Iteration 9\n",
      "INFO:root:loss train : 0.075786\n",
      "INFO:root:loss test : 816.704590\n",
      "INFO:root:loss test forecast : 756.403625\n",
      "INFO:root:Iteration 10\n",
      "INFO:root:loss train : 0.070658\n",
      "INFO:root:loss test : 816.034851\n",
      "INFO:root:loss test forecast : 756.256897\n",
      "INFO:root:Iteration 11\n",
      "INFO:root:loss train : 0.065850\n",
      "INFO:root:loss test : 815.115356\n",
      "INFO:root:loss test forecast : 755.964966\n",
      "INFO:root:Iteration 12\n",
      "INFO:root:loss train : 0.061268\n",
      "INFO:root:loss test : 813.881104\n",
      "INFO:root:loss test forecast : 755.416626\n",
      "INFO:root:Iteration 13\n",
      "INFO:root:loss train : 0.057031\n",
      "INFO:root:loss test : 812.658447\n",
      "INFO:root:loss test forecast : 754.773560\n",
      "INFO:root:Iteration 14\n",
      "INFO:root:loss train : 0.053088\n",
      "INFO:root:loss test : 811.306152\n",
      "INFO:root:loss test forecast : 753.988831\n",
      "INFO:root:Iteration 15\n",
      "INFO:root:loss train : 0.049328\n",
      "INFO:root:loss test : 810.066589\n",
      "INFO:root:loss test forecast : 753.152161\n",
      "INFO:root:Iteration 16\n",
      "INFO:root:loss train : 0.045883\n",
      "INFO:root:loss test : 809.029968\n",
      "INFO:root:loss test forecast : 752.406433\n",
      "INFO:root:Iteration 17\n",
      "INFO:root:loss train : 0.042672\n",
      "INFO:root:loss test : 808.156921\n",
      "INFO:root:loss test forecast : 751.718323\n",
      "INFO:root:Iteration 18\n",
      "INFO:root:loss train : 0.039714\n",
      "INFO:root:loss test : 807.390320\n",
      "INFO:root:loss test forecast : 751.106812\n",
      "INFO:root:Iteration 19\n",
      "INFO:root:loss train : 0.037002\n",
      "INFO:root:loss test : 806.791809\n",
      "INFO:root:loss test forecast : 750.597656\n",
      "INFO:root:Iteration 20\n",
      "INFO:root:loss train : 0.034517\n",
      "INFO:root:loss test : 806.285583\n",
      "INFO:root:loss test forecast : 750.156250\n",
      "INFO:root:Iteration 21\n",
      "INFO:root:loss train : 0.032298\n",
      "INFO:root:loss test : 805.814270\n",
      "INFO:root:loss test forecast : 749.712585\n",
      "INFO:root:Iteration 22\n",
      "INFO:root:loss train : 0.030275\n",
      "INFO:root:loss test : 805.422546\n",
      "INFO:root:loss test forecast : 749.322083\n",
      "INFO:root:Iteration 23\n",
      "INFO:root:loss train : 0.028488\n",
      "INFO:root:loss test : 805.055420\n",
      "INFO:root:loss test forecast : 749.016296\n",
      "INFO:root:Iteration 24\n",
      "INFO:root:loss train : 0.026910\n",
      "INFO:root:loss test : 804.688477\n",
      "INFO:root:loss test forecast : 748.691711\n",
      "INFO:root:Iteration 25\n",
      "INFO:root:loss train : 0.025477\n",
      "INFO:root:loss test : 804.373535\n",
      "INFO:root:loss test forecast : 748.419739\n",
      "INFO:root:Iteration 26\n",
      "INFO:root:loss train : 0.024276\n",
      "INFO:root:loss test : 804.073792\n",
      "INFO:root:loss test forecast : 748.154602\n",
      "INFO:root:Iteration 27\n",
      "INFO:root:loss train : 0.023185\n",
      "INFO:root:loss test : 803.767334\n",
      "INFO:root:loss test forecast : 747.918518\n",
      "INFO:root:Iteration 28\n",
      "INFO:root:loss train : 0.022255\n",
      "INFO:root:loss test : 803.522766\n",
      "INFO:root:loss test forecast : 747.722778\n",
      "INFO:root:Iteration 29\n",
      "INFO:root:loss train : 0.021411\n",
      "INFO:root:loss test : 803.235107\n",
      "INFO:root:loss test forecast : 747.492798\n",
      "INFO:root:Iteration 30\n",
      "INFO:root:loss train : 0.020722\n",
      "INFO:root:loss test : 802.966797\n",
      "INFO:root:loss test forecast : 747.311218\n",
      "INFO:root:Iteration 31\n",
      "INFO:root:loss train : 0.020121\n",
      "INFO:root:loss test : 802.744507\n",
      "INFO:root:loss test forecast : 747.174744\n",
      "INFO:root:Iteration 32\n",
      "INFO:root:loss train : 0.019544\n",
      "INFO:root:loss test : 802.474243\n",
      "INFO:root:loss test forecast : 746.974792\n",
      "INFO:root:Iteration 33\n",
      "INFO:root:loss train : 0.019104\n",
      "INFO:root:loss test : 802.239807\n",
      "INFO:root:loss test forecast : 746.863159\n",
      "INFO:root:Iteration 34\n",
      "INFO:root:loss train : 0.018723\n",
      "INFO:root:loss test : 802.037598\n",
      "INFO:root:loss test forecast : 746.744324\n",
      "INFO:root:Iteration 35\n",
      "INFO:root:loss train : 0.018365\n",
      "INFO:root:loss test : 801.819275\n",
      "INFO:root:loss test forecast : 746.624573\n",
      "INFO:root:Iteration 36\n",
      "INFO:root:loss train : 0.018043\n",
      "INFO:root:loss test : 801.599365\n",
      "INFO:root:loss test forecast : 746.518860\n",
      "INFO:root:Iteration 37\n",
      "INFO:root:loss train : 0.017756\n",
      "INFO:root:loss test : 801.390381\n",
      "INFO:root:loss test forecast : 746.432983\n",
      "INFO:root:Iteration 38\n",
      "INFO:root:loss train : 0.017549\n",
      "INFO:root:loss test : 801.215332\n",
      "INFO:root:loss test forecast : 746.367981\n",
      "INFO:root:Iteration 39\n",
      "INFO:root:loss train : 0.017310\n",
      "INFO:root:loss test : 801.008972\n",
      "INFO:root:loss test forecast : 746.277710\n",
      "INFO:root:Iteration 40\n",
      "INFO:root:loss train : 0.017103\n",
      "INFO:root:loss test : 800.817627\n",
      "INFO:root:loss test forecast : 746.205750\n",
      "INFO:root:Iteration 41\n",
      "INFO:root:loss train : 0.016921\n",
      "INFO:root:loss test : 800.635925\n",
      "INFO:root:loss test forecast : 746.144165\n",
      "INFO:root:Iteration 42\n",
      "INFO:root:loss train : 0.016751\n",
      "INFO:root:loss test : 800.477478\n",
      "INFO:root:loss test forecast : 746.105042\n",
      "INFO:root:Iteration 43\n",
      "INFO:root:loss train : 0.016613\n",
      "INFO:root:loss test : 800.281433\n",
      "INFO:root:loss test forecast : 746.031738\n",
      "INFO:root:Iteration 44\n",
      "INFO:root:loss train : 0.016457\n",
      "INFO:root:loss test : 800.108887\n",
      "INFO:root:loss test forecast : 745.969666\n",
      "INFO:root:Iteration 45\n",
      "INFO:root:loss train : 0.016349\n",
      "INFO:root:loss test : 799.951294\n",
      "INFO:root:loss test forecast : 745.946716\n",
      "INFO:root:Iteration 46\n",
      "INFO:root:loss train : 0.016181\n",
      "INFO:root:loss test : 799.828552\n",
      "INFO:root:loss test forecast : 745.903625\n",
      "INFO:root:Iteration 47\n",
      "INFO:root:loss train : 0.016041\n",
      "INFO:root:loss test : 799.642151\n",
      "INFO:root:loss test forecast : 745.839294\n",
      "INFO:root:Iteration 48\n",
      "INFO:root:loss train : 0.015933\n",
      "INFO:root:loss test : 799.480713\n",
      "INFO:root:loss test forecast : 745.812073\n",
      "INFO:root:Iteration 49\n",
      "INFO:root:loss train : 0.015795\n",
      "INFO:root:loss test : 799.338257\n",
      "INFO:root:loss test forecast : 745.795654\n",
      "INFO:root:Iteration 50\n",
      "INFO:root:loss train : 0.015658\n",
      "INFO:root:loss test : 799.187805\n",
      "INFO:root:loss test forecast : 745.720886\n",
      "INFO:root:Iteration 51\n",
      "INFO:root:loss train : 0.015526\n",
      "INFO:root:loss test : 799.042480\n",
      "INFO:root:loss test forecast : 745.707764\n",
      "INFO:root:Iteration 52\n",
      "INFO:root:loss train : 0.015430\n",
      "INFO:root:loss test : 798.901917\n",
      "INFO:root:loss test forecast : 745.654480\n",
      "INFO:root:Iteration 53\n",
      "INFO:root:loss train : 0.015305\n",
      "INFO:root:loss test : 798.736694\n",
      "INFO:root:loss test forecast : 745.630981\n",
      "INFO:root:Iteration 54\n",
      "INFO:root:loss train : 0.015186\n",
      "INFO:root:loss test : 798.604248\n",
      "INFO:root:loss test forecast : 745.559204\n",
      "INFO:root:Iteration 55\n",
      "INFO:root:loss train : 0.015063\n",
      "INFO:root:loss test : 798.474792\n",
      "INFO:root:loss test forecast : 745.572327\n",
      "INFO:root:Iteration 56\n",
      "INFO:root:loss train : 0.014950\n",
      "INFO:root:loss test : 798.330872\n",
      "INFO:root:loss test forecast : 745.532532\n",
      "INFO:root:Iteration 57\n",
      "INFO:root:loss train : 0.014853\n",
      "INFO:root:loss test : 798.208435\n",
      "INFO:root:loss test forecast : 745.510559\n",
      "INFO:root:Iteration 58\n",
      "INFO:root:loss train : 0.014735\n",
      "INFO:root:loss test : 798.059265\n",
      "INFO:root:loss test forecast : 745.481018\n",
      "INFO:root:Iteration 59\n",
      "INFO:root:loss train : 0.014609\n",
      "INFO:root:loss test : 797.928833\n",
      "INFO:root:loss test forecast : 745.398315\n",
      "INFO:root:Iteration 60\n",
      "INFO:root:loss train : 0.014495\n",
      "INFO:root:loss test : 797.799133\n",
      "INFO:root:loss test forecast : 745.378906\n",
      "INFO:root:Iteration 61\n",
      "INFO:root:loss train : 0.014371\n",
      "INFO:root:loss test : 797.688049\n",
      "INFO:root:loss test forecast : 745.396851\n",
      "INFO:root:Iteration 62\n",
      "INFO:root:loss train : 0.014250\n",
      "INFO:root:loss test : 797.557983\n",
      "INFO:root:loss test forecast : 745.349609\n",
      "INFO:root:Iteration 63\n",
      "INFO:root:loss train : 0.014148\n",
      "INFO:root:loss test : 797.432800\n",
      "INFO:root:loss test forecast : 745.354004\n",
      "INFO:root:Iteration 64\n",
      "INFO:root:loss train : 0.014045\n",
      "INFO:root:loss test : 797.328796\n",
      "INFO:root:loss test forecast : 745.295044\n",
      "INFO:root:Iteration 65\n",
      "INFO:root:loss train : 0.013902\n",
      "INFO:root:loss test : 797.180603\n",
      "INFO:root:loss test forecast : 745.241821\n",
      "INFO:root:Iteration 66\n",
      "INFO:root:loss train : 0.013805\n",
      "INFO:root:loss test : 797.083435\n",
      "INFO:root:loss test forecast : 745.232544\n",
      "INFO:root:Iteration 67\n",
      "INFO:root:loss train : 0.013677\n",
      "INFO:root:loss test : 796.956909\n",
      "INFO:root:loss test forecast : 745.160522\n",
      "INFO:root:Iteration 68\n",
      "INFO:root:loss train : 0.013562\n",
      "INFO:root:loss test : 796.823669\n",
      "INFO:root:loss test forecast : 745.124390\n",
      "INFO:root:Iteration 69\n",
      "INFO:root:loss train : 0.013454\n",
      "INFO:root:loss test : 796.722290\n",
      "INFO:root:loss test forecast : 745.061768\n",
      "INFO:root:Iteration 70\n",
      "INFO:root:loss train : 0.013321\n",
      "INFO:root:loss test : 796.602600\n",
      "INFO:root:loss test forecast : 745.050049\n",
      "INFO:root:Iteration 71\n",
      "INFO:root:loss train : 0.013197\n",
      "INFO:root:loss test : 796.519165\n",
      "INFO:root:loss test forecast : 745.088135\n",
      "INFO:root:Iteration 72\n",
      "INFO:root:loss train : 0.013070\n",
      "INFO:root:loss test : 796.411011\n",
      "INFO:root:loss test forecast : 744.944824\n",
      "INFO:root:Iteration 73\n",
      "INFO:root:loss train : 0.012981\n",
      "INFO:root:loss test : 796.290588\n",
      "INFO:root:loss test forecast : 744.903625\n",
      "INFO:root:Iteration 74\n",
      "INFO:root:loss train : 0.012834\n",
      "INFO:root:loss test : 796.178223\n",
      "INFO:root:loss test forecast : 744.864807\n",
      "INFO:root:Iteration 75\n",
      "INFO:root:loss train : 0.012732\n",
      "INFO:root:loss test : 796.092468\n",
      "INFO:root:loss test forecast : 744.888367\n",
      "INFO:root:Iteration 76\n",
      "INFO:root:loss train : 0.012624\n",
      "INFO:root:loss test : 795.968567\n",
      "INFO:root:loss test forecast : 744.850342\n",
      "INFO:root:Iteration 77\n",
      "INFO:root:loss train : 0.012462\n",
      "INFO:root:loss test : 795.884460\n",
      "INFO:root:loss test forecast : 744.737366\n",
      "INFO:root:Iteration 78\n",
      "INFO:root:loss train : 0.012338\n",
      "INFO:root:loss test : 795.769104\n",
      "INFO:root:loss test forecast : 744.739258\n",
      "INFO:root:Iteration 79\n",
      "INFO:root:loss train : 0.012237\n",
      "INFO:root:loss test : 795.664673\n",
      "INFO:root:loss test forecast : 744.704041\n",
      "INFO:root:Iteration 80\n",
      "INFO:root:loss train : 0.012107\n",
      "INFO:root:loss test : 795.594727\n",
      "INFO:root:loss test forecast : 744.631958\n",
      "INFO:root:Iteration 81\n",
      "INFO:root:loss train : 0.011982\n",
      "INFO:root:loss test : 795.496155\n",
      "INFO:root:loss test forecast : 744.696960\n",
      "INFO:root:Iteration 82\n",
      "INFO:root:loss train : 0.011867\n",
      "INFO:root:loss test : 795.388184\n",
      "INFO:root:loss test forecast : 744.524902\n",
      "INFO:root:Iteration 83\n",
      "INFO:root:loss train : 0.011731\n",
      "INFO:root:loss test : 795.290100\n",
      "INFO:root:loss test forecast : 744.554382\n",
      "INFO:root:Iteration 84\n",
      "INFO:root:loss train : 0.011612\n",
      "INFO:root:loss test : 795.200439\n",
      "INFO:root:loss test forecast : 744.538879\n",
      "INFO:root:Iteration 85\n",
      "INFO:root:loss train : 0.011487\n",
      "INFO:root:loss test : 795.104187\n",
      "INFO:root:loss test forecast : 744.432251\n",
      "INFO:root:Iteration 86\n",
      "INFO:root:loss train : 0.011378\n",
      "INFO:root:loss test : 795.008545\n",
      "INFO:root:loss test forecast : 744.406860\n",
      "INFO:root:Iteration 87\n",
      "INFO:root:loss train : 0.011232\n",
      "INFO:root:loss test : 794.912842\n",
      "INFO:root:loss test forecast : 744.343628\n",
      "INFO:root:Iteration 88\n",
      "INFO:root:loss train : 0.011120\n",
      "INFO:root:loss test : 794.816833\n",
      "INFO:root:loss test forecast : 744.281616\n",
      "INFO:root:Iteration 89\n",
      "INFO:root:loss train : 0.011011\n",
      "INFO:root:loss test : 794.723328\n",
      "INFO:root:loss test forecast : 744.233093\n",
      "INFO:root:Iteration 90\n",
      "INFO:root:loss train : 0.010885\n",
      "INFO:root:loss test : 794.634644\n",
      "INFO:root:loss test forecast : 744.210327\n",
      "INFO:root:Iteration 91\n",
      "INFO:root:loss train : 0.010753\n",
      "INFO:root:loss test : 794.533569\n",
      "INFO:root:loss test forecast : 744.114563\n",
      "INFO:root:Iteration 92\n",
      "INFO:root:loss train : 0.010647\n",
      "INFO:root:loss test : 794.439819\n",
      "INFO:root:loss test forecast : 744.084595\n",
      "INFO:root:Iteration 93\n",
      "INFO:root:loss train : 0.010531\n",
      "INFO:root:loss test : 794.341553\n",
      "INFO:root:loss test forecast : 744.011658\n",
      "INFO:root:Iteration 94\n",
      "INFO:root:loss train : 0.010394\n",
      "INFO:root:loss test : 794.250916\n",
      "INFO:root:loss test forecast : 744.016846\n",
      "INFO:root:Iteration 95\n",
      "INFO:root:loss train : 0.010286\n",
      "INFO:root:loss test : 794.163452\n",
      "INFO:root:loss test forecast : 743.902954\n",
      "INFO:root:Iteration 96\n",
      "INFO:root:loss train : 0.010159\n",
      "INFO:root:loss test : 794.076172\n",
      "INFO:root:loss test forecast : 743.854797\n",
      "INFO:root:Iteration 97\n",
      "INFO:root:loss train : 0.010054\n",
      "INFO:root:loss test : 793.977966\n",
      "INFO:root:loss test forecast : 743.874695\n",
      "INFO:root:Iteration 98\n",
      "INFO:root:loss train : 0.009941\n",
      "INFO:root:loss test : 793.857117\n",
      "INFO:root:loss test forecast : 743.704529\n",
      "INFO:root:Iteration 99\n",
      "INFO:root:loss train : 0.009809\n",
      "INFO:root:loss test : 793.786560\n",
      "INFO:root:loss test forecast : 743.703552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (encoder): Linear(in_features=40, out_features=10, bias=True)\n",
       "  (latent): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(rnn, decoder, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyth-torch-numpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
